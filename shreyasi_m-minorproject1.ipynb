{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa06700b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAD7CAYAAAAVQzPHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXSklEQVR4nO3de2xU1fYH8O8SxRcRKSpWQFBTq/gLvhDRi1oFDBc14AOVqEAk1kQwaNCAXjQaX/giUcQHUV5KwGsQQQ1BUguGiA2geC9QS9EELDYgvkBQuej6/dHj9uxjp53OnNfM/n6SZtaePTNnSZer55w5D1FVEBEVu4OSToCIKA5sdkTkBDY7InICmx0ROYHNjoicwGZHRE7Iq9mJyGARqRORLSIyKaykiJLG2i4+kutxdiLSDsBmAIMANABYA2CEqm4KLz2i+LG2i9PBeby3L4AtqvoVAIjIAgBDAWQsCBHhEczpsUtVj006iZRibRcwVZXmns9nM7YrgK994wbvOSoMW5NOIMVY20UonzW75rrn3/66iUglgMo8lkMUN9Z2Ecqn2TUA6O4bdwPwTfBFqjoDwAyAq/pUMFjbRSifzdg1AMpE5CQRaQ/gRgBLwkmLKFGs7SKU85qdqh4QkXEAlgFoB2Cmqm4MLTOihLC2i1POh57ktDCu6qfJOlXtk3QSxYK1nR5RfBtLRFQw2OyIyAlsdkTkBDY7InICmx0ROYHNjoicwGZHRE7I53QxIipi5557rjUeN26ciUeOHGnNzZ0718TTpk2z5j799NMIsms7rtkRkRPY7IjICWx2ROQEnhvbjHbt2lnjjh07Zv1e/36NI444wporLy838dixY625Z555xsQjRoyw5n799VcTT5kyxZp7+OGHs84tgOfGhqhQarslZ511ljX+8MMPrfFRRx2V1ef89NNP1rhz58555dVWPDeWiJzGZkdETijqQ09OPPFEa9y+fXsTX3jhhdZc//79TXz00Udbc9dee20o+TQ0NJj4+eeft+auvvpqE+/Zs8ea+/zzz028cuXKUHIhAoC+ffuaeOHChdZccPeNf5dXsEb3799v4uBma79+/UwcPAzF/76occ2OiJzAZkdETmCzIyInFN2hJ/6vz4NfnbflEJIw/PHHH9b41ltvNfHPP/+c8X2NjY3W+IcffjBxXV1dSNnx0JMwpfnQE/8hUOecc44198Ybb5i4W7du1pyIfQSHv1cE97099dRTJl6wYEHGz5k8ebI198QTT7SYey546AkROY3NjoicUHSHnmzbts3E3333nTUXxmZsTU2NNf7xxx+t8aWXXmri4Nfqr7/+et7LJ2qrV155xcTBs3NyFdwc7tChg4mDh0dVVFSYuHfv3qEsPxdcsyMiJ7DZEZET2OyIyAlFt8/u+++/N/G9995rzV155ZUm/uyzz6y54OlbfuvXrzfxoEGDrLm9e/da4zPOOMPE48ePbz1hopAFrzB8xRVXmDh4OIlfcF/bu+++a439V+b55ptvrDn//0/+Q6UA4LLLLstq+VFrdc1ORGaKyE4R2eB7rkRElotIvffYKdo0icLH2nZLNpuxswEMDjw3CUCVqpYBqPLGRIVmNljbzsjqDAoR6QngPVX9P29cB6BCVRtFpBTAClUtb+kzvPclepS5/+KDwas2+L+eHzNmjDV38803m3j+/PkRZRc7nkGB4qntls4caumim0uXLjVx8LCUSy65xBr7Dxt59dVXrblvv/024zJ+//13E+/bty/jMsK6MU/YZ1B0UdVG74MbARyXa2JEKcPaLlKRf0EhIpUAKqNeDlHcWNuFJdc1ux3eKj68x52ZXqiqM1S1DzeZqECwtotUrmt2SwCMAjDFe1wcWkYR2r17d8a54E1C/G677TYTv/nmm9Zc8MomVPAKorZPPfVUa+w/zCp4WuSuXbtMHLyizpw5c0wcvBLP+++/3+I4F4cffrg1njBhgolvuummvD+/JdkcejIfwGoA5SLSICJj0FQIg0SkHsAgb0xUUFjbbml1zU5VM505PCDkXIhixdp2S9GdQZGrhx56yMTBI9D9X48PHDjQmvvggw8izYvoT4ceeqiJ/WczAMCQIUNMHDysauTIkSZeu3atNRfcrIxb8KZYUeK5sUTkBDY7InICmx0ROaHobrgThlNOOcUa+09jCV6ZuLq62hr794lMnz7dmovz3zoLPF0sRHHUtv9m06tWrcr4ugED7O9Xkr6xuv90seD/A6tXrzbxRRddFMryeMMdInIamx0ROYGHnjTjyy+/tMajR4828axZs6y5W265JeP4yCOPtObmzp1r4uCR7EStmTp1qomDF8H0b6omvdkadNBBf61TJXnGEdfsiMgJbHZE5AQ2OyJyAvfZZWHRokUmrq+vt+b8+1EA+2v/xx9/3Jrr0aOHiR977DFrbvv27XnnScXFf4MowL4acfAQjiVLlsSRUk78++mCeftvZhU1rtkRkRPY7IjICWx2ROQE7rNrow0bNljj66+/3hpfddVVJg4ek3f77bebuKyszJoL3nybKHj5pfbt25t45077avHBK2jHzX/5Kf/l0oKCdz677777okrpb7hmR0ROYLMjIidwMzZPwaugvP766yYO3kj44IP/+ue++OKLrbmKigoTr1ixIrT8qDj99ttv1jju0w/9m60AMHnyZBP7b/4DAA0NDSZ+9tlnrbngTX6ixDU7InICmx0ROYHNjoicwH12bdS7d29rfN1111nj8847z8T+fXRBmzZtssYfffRRCNmRK5I4Pcx/ulpwv9wNN9xg4sWL7fuKX3vttZHmlS2u2RGRE9jsiMgJ3IxtRnl5uTUeN26cia+55hpr7vjjj8/6c/03HgkeKpDkFVwpnYJXI/aPhw0bZs2NHz8+9OXffffd1viBBx4wcceOHa25efPmmdh/U+404ZodETmh1WYnIt1FpFpEakVko4iM954vEZHlIlLvPXaKPl2i8LC23ZLNmt0BABNU9XQA/QCMFZFeACYBqFLVMgBV3piokLC2HdLqPjtVbQTQ6MV7RKQWQFcAQwFUeC+bA2AFgImRZBmB4L62ESNGmNi/jw4AevbsmdMy/DfMBuyrE6f5yrKuSHttB6/q6x8H6/f555838cyZM6257777zsT+G20D9t3wzjzzTGuuW7du1njbtm0mXrZsmTX34osv/v0/IGXatM9ORHoCOBtADYAuXrH8WTTHhZ4dUUxY28Uv629jRaQDgIUA7lLV3cFvilp4XyWAytzSI4oea9sNElxVbvZFIocAeA/AMlWd6j1XB6BCVRtFpBTAClUtb+VzWl9YiLp06WKNe/XqZeIXXnjBmjvttNNyWkZNTY01fvrpp00cPJI8ZYeXrFPVPkknkbQ01/bw4cOt8fz587N6344dO6zx7t27TRy8aGxLVq9ebY2rq6tN/OCDD2b9OXFT1Wb/WmXzbawAeA1A7Z/F4FkCYJQXjwKwOPheojRjbbslm83YfwC4BcB/RWS999z9AKYA+LeIjAGwDcDw5t9OlFqsbYdk823sKgCZdmIMyPA8Ueqxtt2S1T670BYWwX6NkpISa/zKK6+Y2H+VBgA4+eSTc1rGxx9/bOLglVaDX8H/8ssvOS0jAdxnF6Ioajt46Mdbb71lYv/VdZrJxRq39P+4/7CUBQsWWHNRnIIWh5z32RERFQM2OyJyQkFsxp5//vnW2H/hwL59+1pzXbt2zWUR2Ldvn4n9R6MDwOOPP27ivXv35vT5KcTN2BDFcVhVaWmpif33IAbsG960tBn73HPPWXMvvfSSibds2RJKnknjZiwROY3NjoicwGZHRE4oiH12U6ZMscbBm31kErypzXvvvWfiAwcOWHP+Q0qCN74uUtxnF6K4T4WkzLjPjoicxmZHRE4oiM1YigQ3Y0PE2k4PbsYSkdPY7IjICWx2ROQENjsicgKbHRE5gc2OiJzAZkdETmCzIyInsNkRkRPY7IjICdncSjFMuwBsBXCMF6eBq7n0iGk5rtgFYC/SU0uAm7Wdsa5jPTfWLFRkbVrOy2QuFJa0/f7SlE8acuFmLBE5gc2OiJyQVLObkdBym8NcKCxp+/2lKZ/Ec0lknx0RUdy4GUtEToi12YnIYBGpE5EtIjIpzmV7y58pIjtFZIPvuRIRWS4i9d5jp5hy6S4i1SJSKyIbRWR8kvlQfpKsbdZ1dmJrdiLSDsB0AP8E0AvACBHpFdfyPbMBDA48NwlAlaqWAajyxnE4AGCCqp4OoB+Asd6/R1L5UI5SUNuzwbpuVZxrdn0BbFHVr1R1P4AFAIbGuHyo6kcAvg88PRTAHC+eA2BYTLk0quqnXrwHQC2ArknlQ3lJtLZZ19mJs9l1BfC1b9zgPZe0LqraCDT9ogAcF3cCItITwNkAatKQD7VZGms78TpKW13H2eyau+OP818Fi0gHAAsB3KWqu5POh3LC2g5IY13H2ewaAHT3jbsB+CbG5WeyQ0RKAcB73BnXgkXkEDQVxDxVfTvpfChnaaxt1nVAnM1uDYAyETlJRNoDuBHAkhiXn8kSAKO8eBSAxXEsVEQEwGsAalV1atL5UF7SWNus6yBVje0HwBAAmwF8CeBfcS7bW/58AI0A/oemv8ZjAHRG07dD9d5jSUy59EfTps5/AKz3foYklQ9/8v59JlbbrOvsfngGBRE5gWdQEJET2OyIyAl5NbukT/8iigpru/jkvM/OO0VmM4BBaNopugbACFXdFF56RPFjbRenfO5BYU6RAQAR+fMUmYwFISL8NiQ9dqnqsUknkVKs7QKmqs0d5J3XZmwaT5Gh7G1NOoEUY20XoXzW7LI6RUZEKgFU5rEcorixtotQPs0uq1NkVHUGvEsyc1WfCgRruwjlsxmbxlNkiMLA2i5COa/ZqeoBERkHYBmAdgBmqurG0DIjSghruzjFeroYV/VTZZ2m5AbKxYC1nR5RfBtLRFQw2OyIyAlsdkTkBDY7InICmx0ROYHNjoicwGZHRE5gsyMiJ7DZEZET2OyIyAlsdkTkhHwu8UQhGjBggInnzZtnzV1yySUmrquriy0nomxNnjzZxA8//LA1d9BBf61TVVRUWHMrV66MNC8rj9iWRESUIDY7InJCQWzGXnzxxda4c+fOJl60aFHc6UTivPPOM/GaNWsSzISodaNHj7bGEydONPEff/yR8X1xXlIuiGt2ROQENjsicgKbHRE5oSD22QW/ri4rKzNxoe6z838dDwAnnXSSiXv06GHNiTR7lWmixARr9LDDDksok+xxzY6InMBmR0ROKIjN2JEjR1rj1atXJ5RJeEpLS63xbbfdZuI33njDmvviiy9iyYmoJQMHDjTxnXfemfF1wXq98sorTbxjx47wE8sS1+yIyAlsdkTkBDY7InJCQeyzCx6mUQxeffXVjHP19fUxZkLUvP79+1vjWbNmmbhjx44Z3/f0009b461bt4abWI5a7SIiMlNEdorIBt9zJSKyXETqvcdO0aZJFD7WtluyWWWaDWBw4LlJAKpUtQxAlTcmKjSzwdp2Rqubsar6kYj0DDw9FECFF88BsALARISod+/eJu7SpUuYH50KLW0GLF++PMZM3JVUbReKUaNGWeMTTjgh42tXrFhh4rlz50aVUl5y3RnWRVUbAcB7PC68lIgSxdouUpF/QSEilQAqo14OUdxY24Ul1zW7HSJSCgDe485ML1TVGaraR1X75LgsojixtotUrmt2SwCMAjDFe1wcWkaeIUOGmPjwww8P++MT4d/36L/KSdD27dvjSIeaF3ltp9UxxxxjjW+99VZr7L8C8Y8//mjNPfroo5HlFZZsDj2ZD2A1gHIRaRCRMWgqhEEiUg9gkDcmKiisbbdk823siAxTAzI8T1QQWNtuSe0ZFOXl5RnnNm7cGGMm4XnmmWdMHDycZvPmzSbes2dPbDmR23r27GnihQsXZv2+adOmWePq6uqwUopM8Z2HRUTUDDY7InICmx0ROSG1++xakqabSB911FHWePDgv061vPnmm625yy+/POPnPPLIIyYOfq1PFBV/vfpP0WxOVVWViZ977rnIcooK1+yIyAlsdkTkhILcjC0pKcnpfWeeeaaJg/di9d9MpFu3btZc+/btTXzTTTdZc8ELi/7yyy8mrqmpseZ+++03Ex98sP1Pv27duhZzJwrDsGHDrPGUKZmPmV61apU19l8F5aeffgo1rzhwzY6InMBmR0ROYLMjIiekdp+df9+XqlpzL7/8sonvv//+rD/T/9V6cJ/dgQMHTLxv3z5rbtOmTSaeOXOmNbd27VprvHLlShMHbwjc0NBg4uCVXHgjbIpKrqeEffXVV9Y4yRtch4FrdkTkBDY7InICmx0ROSG1++zuuOMOEwdvsnvhhRfm9Jnbtm0z8TvvvGPN1dbWmviTTz7J6fODKivt2xMce+yxJg7uDyGKysSJf90czX+14da0dAxeIeKaHRE5gc2OiJyQ2s1YvyeffDLpFHIyYEDmq3u35RAAorY466yzrHFLV9vxW7zYvrdQXV1dWCmlAtfsiMgJbHZE5AQ2OyJyQkHssytGixYtSjoFKlIffPCBNe7UqVPG1/oPsxo9enRUKaUC1+yIyAlsdkTkBG7GEhWZzp07W+OWzpp48cUXTfzzzz9HllMatLpmJyLdRaRaRGpFZKOIjPeeLxGR5SJS7z1m3jFAlEKsbbdksxl7AMAEVT0dQD8AY0WkF4BJAKpUtQxAlTcmKiSsbYe02uxUtVFVP/XiPQBqAXQFMBTAHO9lcwAMiyhHokiwtt3Spn12ItITwNkAagB0UdVGoKloROS48NMrLv6rI5966qnWXFhXWqHcFHptz5o1y8TBO9615OOPP44inVTKutmJSAcACwHcpaq7g5c1b+F9lQAqW30hUUJY227I6k+AiByCpmKYp6pve0/vEJFSb74UwM7m3quqM1S1j6r2CSNhojCxtt3R6pqdNP2Zew1ArapO9U0tATAKwBTvcXEzbycf/42D2rKpQdEo5NoOXtnEf5P34KEm+/fvN/H06dOtuUK/iU5bZLMZ+w8AtwD4r4is9567H02F8G8RGQNgG4DhkWRIFB3WtkNabXaqugpApp0YmS/YRpRyrG23cFuKiJzA08UScsEFF1jj2bNnJ5MIFaSjjz7aGh9//PEZX7t9+3YT33PPPVGllHpcsyMiJ7DZEZETuBkbo2wPViWi8HHNjoicwGZHRE5gsyMiJ3CfXYSWLl1qjYcP54H4FI4vvvjCGvuvXtK/f/+40ykIXLMjIiew2RGRE8R/JY7IFyYS38KoNet4aaLwsLbTQ1WbPcaLa3ZE5AQ2OyJyApsdETmBzY6InMBmR0ROYLMjIiew2RGRE9jsiMgJbHZE5AQ2OyJyQtxXPdkFYCuAY7w4DVzNpUdMy3HFLgB7kZ5aAtys7Yx1Heu5sWahImvTcl4mc6GwpO33l6Z80pALN2OJyAlsdkTkhKSa3YyEltsc5kJhSdvvL035JJ5LIvvsiIjixs1YInJCrM1ORAaLSJ2IbBGRSXEu21v+TBHZKSIbfM+ViMhyEan3HjvFlEt3EakWkVoR2Sgi45PMh/KTZG2zrrMTW7MTkXYApgP4J4BeAEaISK+4lu+ZDWBw4LlJAKpUtQxAlTeOwwEAE1T1dAD9AIz1/j2SyodylILang3WdaviXLPrC2CLqn6lqvsBLAAwNMblQ1U/AvB94OmhAOZ48RwAw2LKpVFVP/XiPQBqAXRNKh/KS6K1zbrOTpzNriuAr33jBu+5pHVR1Uag6RcF4Li4ExCRngDOBlCThnyozdJY24nXUdrqOs5m19wdf5z/KlhEOgBYCOAuVd2ddD6UE9Z2QBrrOs5m1wCgu2/cDcA3MS4/kx0iUgoA3uPOuBYsIoegqSDmqerbSedDOUtjbbOuA+JsdmsAlInISSLSHsCNAJbEuPxMlgAY5cWjACyOY6EiIgBeA1CrqlOTzofyksbaZl0HqWpsPwCGANgM4EsA/4pz2d7y5wNoBPA/NP01HgOgM5q+Har3HktiyqU/mjZ1/gNgvfczJKl8+JP37zOx2mZdZ/fDMyiIyAk8g4KInMBmR0ROYLMjIiew2RGRE9jsiMgJbHZE5AQ2OyJyApsdETnh/wGmetwHakoisQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ad hoc mnist instances\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "# load (downloaded if needed) the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "023b8820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2479f4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f155db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape((X_train.shape[0], num_pixels)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], num_pixels)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e5d1fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e2e53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52062763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(num_pixels, input_shape=(num_pixels,), kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7acacb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 3s - loss: 0.2801 - accuracy: 0.9199 - val_loss: 0.1405 - val_accuracy: 0.9596 - 3s/epoch - 9ms/step\n",
      "Epoch 2/10\n",
      "300/300 - 2s - loss: 0.1100 - accuracy: 0.9690 - val_loss: 0.0984 - val_accuracy: 0.9709 - 2s/epoch - 7ms/step\n",
      "Epoch 3/10\n",
      "300/300 - 2s - loss: 0.0712 - accuracy: 0.9787 - val_loss: 0.0749 - val_accuracy: 0.9785 - 2s/epoch - 7ms/step\n",
      "Epoch 4/10\n",
      "300/300 - 2s - loss: 0.0498 - accuracy: 0.9857 - val_loss: 0.0697 - val_accuracy: 0.9782 - 2s/epoch - 7ms/step\n",
      "Epoch 5/10\n",
      "300/300 - 2s - loss: 0.0365 - accuracy: 0.9897 - val_loss: 0.0705 - val_accuracy: 0.9772 - 2s/epoch - 7ms/step\n",
      "Epoch 6/10\n",
      "300/300 - 2s - loss: 0.0265 - accuracy: 0.9929 - val_loss: 0.0639 - val_accuracy: 0.9797 - 2s/epoch - 7ms/step\n",
      "Epoch 7/10\n",
      "300/300 - 2s - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.0675 - val_accuracy: 0.9804 - 2s/epoch - 7ms/step\n",
      "Epoch 8/10\n",
      "300/300 - 2s - loss: 0.0137 - accuracy: 0.9970 - val_loss: 0.0609 - val_accuracy: 0.9818 - 2s/epoch - 7ms/step\n",
      "Epoch 9/10\n",
      "300/300 - 2s - loss: 0.0102 - accuracy: 0.9980 - val_loss: 0.0577 - val_accuracy: 0.9814 - 2s/epoch - 7ms/step\n",
      "Epoch 10/10\n",
      "300/300 - 2s - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.0587 - val_accuracy: 0.9829 - 2s/epoch - 6ms/step\n",
      "Baseline Error: 1.71%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f163c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 6s - loss: 0.2803 - accuracy: 0.9205 - val_loss: 0.1421 - val_accuracy: 0.9576 - 6s/epoch - 20ms/step\n",
      "Epoch 2/10\n",
      "300/300 - 4s - loss: 0.1128 - accuracy: 0.9667 - val_loss: 0.0948 - val_accuracy: 0.9713 - 4s/epoch - 13ms/step\n",
      "Epoch 3/10\n",
      "300/300 - 4s - loss: 0.0718 - accuracy: 0.9798 - val_loss: 0.0816 - val_accuracy: 0.9745 - 4s/epoch - 13ms/step\n",
      "Epoch 4/10\n",
      "300/300 - 4s - loss: 0.0518 - accuracy: 0.9845 - val_loss: 0.0670 - val_accuracy: 0.9787 - 4s/epoch - 13ms/step\n",
      "Epoch 5/10\n",
      "300/300 - 4s - loss: 0.0370 - accuracy: 0.9893 - val_loss: 0.0597 - val_accuracy: 0.9812 - 4s/epoch - 13ms/step\n",
      "Epoch 6/10\n",
      "300/300 - 4s - loss: 0.0268 - accuracy: 0.9929 - val_loss: 0.0671 - val_accuracy: 0.9794 - 4s/epoch - 13ms/step\n",
      "Epoch 7/10\n",
      "300/300 - 4s - loss: 0.0191 - accuracy: 0.9952 - val_loss: 0.0607 - val_accuracy: 0.9809 - 4s/epoch - 13ms/step\n",
      "Epoch 8/10\n",
      "300/300 - 4s - loss: 0.0142 - accuracy: 0.9967 - val_loss: 0.0589 - val_accuracy: 0.9818 - 4s/epoch - 13ms/step\n",
      "Epoch 9/10\n",
      "300/300 - 4s - loss: 0.0110 - accuracy: 0.9978 - val_loss: 0.0604 - val_accuracy: 0.9829 - 4s/epoch - 13ms/step\n",
      "Epoch 10/10\n",
      "300/300 - 4s - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.0593 - val_accuracy: 0.9826 - 4s/epoch - 13ms/step\n",
      "Baseline Error: 1.74%\n"
     ]
    }
   ],
   "source": [
    "# Baseline MLP for MNIST dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape((X_train.shape[0], num_pixels)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], num_pixels)).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "# define baseline model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(num_pixels, input_shape=(num_pixels,), kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07a87f",
   "metadata": {},
   "source": [
    "# Simple Convolitional Neural Network for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1bff191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27fb3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][width][height][channels]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85f404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bb44d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ff3d19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 28s - loss: 0.2362 - accuracy: 0.9317 - val_loss: 0.0787 - val_accuracy: 0.9752 - 28s/epoch - 95ms/step\n",
      "Epoch 2/10\n",
      "300/300 - 26s - loss: 0.0741 - accuracy: 0.9781 - val_loss: 0.0551 - val_accuracy: 0.9829 - 26s/epoch - 87ms/step\n",
      "Epoch 3/10\n",
      "300/300 - 26s - loss: 0.0521 - accuracy: 0.9840 - val_loss: 0.0438 - val_accuracy: 0.9858 - 26s/epoch - 87ms/step\n",
      "Epoch 4/10\n",
      "300/300 - 27s - loss: 0.0403 - accuracy: 0.9879 - val_loss: 0.0369 - val_accuracy: 0.9887 - 27s/epoch - 89ms/step\n",
      "Epoch 5/10\n",
      "300/300 - 27s - loss: 0.0316 - accuracy: 0.9905 - val_loss: 0.0401 - val_accuracy: 0.9856 - 27s/epoch - 89ms/step\n",
      "Epoch 6/10\n",
      "300/300 - 26s - loss: 0.0274 - accuracy: 0.9912 - val_loss: 0.0331 - val_accuracy: 0.9885 - 26s/epoch - 87ms/step\n",
      "Epoch 7/10\n",
      "300/300 - 27s - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0335 - val_accuracy: 0.9901 - 27s/epoch - 89ms/step\n",
      "Epoch 8/10\n",
      "300/300 - 26s - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.0351 - val_accuracy: 0.9877 - 26s/epoch - 86ms/step\n",
      "Epoch 9/10\n",
      "300/300 - 26s - loss: 0.0156 - accuracy: 0.9948 - val_loss: 0.0328 - val_accuracy: 0.9884 - 26s/epoch - 86ms/step\n",
      "Epoch 10/10\n",
      "300/300 - 26s - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.0328 - val_accuracy: 0.9892 - 26s/epoch - 86ms/step\n",
      "CNN Error: 1.08%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d79fb8",
   "metadata": {},
   "source": [
    "# Large Convolutional Neural Network for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfafd6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Larger CNN for the MNIST Dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][width][height][channels]\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4504edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the larger model\n",
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b37a807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 31s 97ms/step - loss: 0.3883 - accuracy: 0.8784 - val_loss: 0.1060 - val_accuracy: 0.9683\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 29s 96ms/step - loss: 0.1084 - accuracy: 0.9660 - val_loss: 0.0679 - val_accuracy: 0.9781\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 29s 95ms/step - loss: 0.0749 - accuracy: 0.9767 - val_loss: 0.0466 - val_accuracy: 0.9848\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 30s 101ms/step - loss: 0.0590 - accuracy: 0.9819 - val_loss: 0.0365 - val_accuracy: 0.9884\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 29s 97ms/step - loss: 0.0516 - accuracy: 0.9838 - val_loss: 0.0399 - val_accuracy: 0.9875\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 28s 95ms/step - loss: 0.0455 - accuracy: 0.9859 - val_loss: 0.0317 - val_accuracy: 0.9903\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 29s 95ms/step - loss: 0.0411 - accuracy: 0.9870 - val_loss: 0.0282 - val_accuracy: 0.9900\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 29s 95ms/step - loss: 0.0367 - accuracy: 0.9878 - val_loss: 0.0271 - val_accuracy: 0.9913\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 29s 96ms/step - loss: 0.0335 - accuracy: 0.9894 - val_loss: 0.0293 - val_accuracy: 0.9909\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 29s 95ms/step - loss: 0.0316 - accuracy: 0.9899 - val_loss: 0.0250 - val_accuracy: 0.9914\n",
      "Large CNN Error: 0.86%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ab34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
